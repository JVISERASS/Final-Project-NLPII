{
  "framework": "transformers_peft",
  "training_time_seconds": 3201.1012506484985,
  "training_time_minutes": 53.35168751080831,
  "peak_memory_gb": 2.23583984375,
  "train_loss": 1.4130176904466416,
  "train_samples": 12000,
  "epochs": 3,
  "effective_batch_size": 16,
  "lora_rank": 16,
  "learning_rate": 0.0002,
  "timestamp": "2025-12-31T00:33:15.274106",
  "eval_loss": 1.3517913818359375
}